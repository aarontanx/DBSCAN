import numpy as np
import pandas as pd
from sklearn import metrics
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score

def compute_silhouette(df, cluster_count=10, min_cluster = 2):
    """
    df should consist of only scaled features
    Perform loop to compute which cluster n give the best score, and return n_clus, max_sil and labels_true
    """
    cluster_count += 1
    cluster = list(np.arange(cluster_count))[min_cluster:]

    # initialize max_silhouette score and best number of clusters
    max_sil = 0
    n_clus = 0

    for i in cluster:
        kmeans = KMeans(n_clusters = i, random_state = 123).fit(df)
        cluster_labels = kmeans.predict(df)
        
        """
        The silhouette score gives the average value for all the samples.
        This gives a perspective into density and separation of formed clusters
        """
        silhouette_avg = silhouette_score(df, cluster_labels)
        
        # Avg silhoutte score
        print(' '.join(["For n_clusters = ", str(i), "The average silhouette_score is : ", str(silhouette_avg)]))
        
        if silhouette_avg > max_sil:
            max_sil = silhouette_avg
            n_clus = i
            labels_true = kmeans.labels_

    print(''.join(['Best n_cluster: ', str(n_clus), '. Best silhouette score: ', str(max_sil)]))
    """
    Return optimal n_cluster, silhouette score and labels. The labels is then used to compare against DBSCAN result for score.
    """
    return n_clus, max_sil, labels_true

def find_optimal(df, eps, min_samples, labels_true):
    """
    prepare the param to test with
    prepare list of potential epsilon sie and min_number of samples:
    example:
    eps = list(np.linspace(0.1, 0.4, 10))
    min_samples = list(np.arange(80, 250, 40))
    Import labels generated by kmeans from compute_silhouette to compare the ground truth. More for analysis use if you want to compare kmean vs dbscan score. 
    Can actually remove it from script if don't want to compare the scores.
    """

    df_results = pd.DataFrame(columns = ['iteration', 'eps', 'min_samples', 'error', 'num_error'])
    print("Loop through the EPS and min sample list to find optimal outlier size.")

    iteration_num = 0

    for i in eps: 
        population = df.shape[0]
        
        for j in min_samples:
            iteration_num += 1
            iteration = 'Iteration %0.0f' % iteration_num
            print('')
            print(str(iteration))
            
            model = DBSCAN(eps = i, min_samples = j, algorithm = 'auto', n_jobs = -1).fit(df)
        
            core_samples_mask = np.zeros_like(model.labels_, dtype = bool)
            core_samples_mask[model.core_sample_indices_] = True
            labels = model.labels_
        
            # If no outlier will continue to run instead of stopping
            try:
                anomaly = pd.Series(list(labels)).value_counts()[-1] 
            except:
                anomaly = 0

            n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
            n_noise_ = list(labels).count(-1)
            error = anomaly / population
        
            if n_clusters_ == 0:
                print(' '.join(['eps = ', str(i), 'min, samples =', str(j)]))
                print('')
                continue
            else:
                print(' '.join(['eps= ', str(i), 'min_samples = ', str(j)]))
                print(' '.join(['Estimated number of clusters:', str(n_clusters_)]))
                print(' '.join(['Estimated number of noise points', str(n_noise_)]))
                print(' '.join(['Homogeneity:', str(round(metrics.homogeneity_score(labels_true, labels), 3))]))
                print(' '.join(['Completeness:', str(round(metrics.completeness_score(labels_true, labels), 3))]))
                print(' '.join(['V-measure:', str(round(metrics.v_measure_score(labels_true, labels), 3))]))
                print(' '.join(['Adjusted Rand Index:', str(round(metrics.adjusted_rand_score(labels_true, labels), 3))]))
                print(' '.join(['Percentage Outliers:', str(round(error*100, 3)), '%']))
                print('')
            
                param = pd.DataFrame({'iteration': [iteration_num],
                    'eps': [i],
                    'min_samples': [j],
                    'error': [error],
                    'n_clusters': [n_clusters_],
                    'num_error': [anomaly]})
                
                df_results = pd.concat([df_results, param])
    
    return df_results

def model_generation(df, eps, min_samples, labels_true):
    print(''.join(['Selecting EPS: ', str(eps), ", min_samples: ", str(min_samples)]))
    print('Running model with defined param.')

    population = df.shape[0]

    model = DBSCAN(eps = eps, min_samples = min_samples, algorithm = 'auto', n_jobs = -1).fit(df)
        
    core_samples_mask = np.zeros_like(model.labels_, dtype = bool)
    core_samples_mask[model.core_sample_indices_] = True
    labels = model.labels_

    anomaly = pd.Series(list(labels)).value_counts()[-1] 

    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
    n_noise_ = list(labels).count(-1)
    error = anomaly / population

    print(' '.join(['eps= ', str(eps), 'min_samples = ', str(min_samples)]))
    print(' '.join(['Estimated number of clusters:', str(n_clusters_)]))
    print(' '.join(['Estimated number of noise points', str(n_noise_)]))
    print(' '.join(['Homogeneity:', str(round(metrics.homogeneity_score(labels_true, labels), 3))]))
    print(' '.join(['Completeness:', str(round(metrics.completeness_score(labels_true, labels), 3))]))
    print(' '.join(['V-measure:', str(round(metrics.v_measure_score(labels_true, labels), 3))]))
    print(' '.join(['Adjusted Rand Index:', str(round(metrics.adjusted_rand_score(labels_true, labels), 3))]))
    print(' '.join(['Percentage Outliers:', str(round(error*100, 3)), '%']))
    print('')
    return model
